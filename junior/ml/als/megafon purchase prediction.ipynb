{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/user/andrey.chubin/check_point_dir': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -R /user/andrey.chubin/check_point_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -R /user/andrey.chubin/w_test_adj.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -get /labs/lab10data/lab10_views_programmes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -ls /user/andrey.chubin/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Запускаю Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 6 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"andrey lab10 app\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"andrey lab10 app\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Устанавливаю папку для чекпоинта на всякий случай"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setCheckpointDir(\"/user/andrey.chubin/check_point_dir/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_schema = StructType(fields=[StructField(\"user_id\", StringType()),\n",
    "                               StructField(\"item_id\", StringType()),\n",
    "                               StructField(\"purchase\", DoubleType())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загружаю файлы. В файле с информацией о фильмах и программах сразу превращаю год создания в возраст в годах (математические операции с возрастом имеют больше смысла чем с годом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.read.csv(\"/labs/lab10data/lab10_test.csv\", sep=',', header=True, schema=t_schema)\n",
    "\n",
    "train = spark.read.csv(\"/labs/lab10data/lab10_train.csv\", sep=',', header=True, schema=t_schema)\n",
    "\n",
    "items = spark.read.csv(\"/labs/lab10data/lab10_items.csv\", sep='\\t', header=True)\\\n",
    ".where(f.col('content_type')=='1')\\\n",
    ".select('item_id', 'year', 'genres')\\\n",
    ".select(f.col('item_id'), (2020 - f.col('year').cast(IntegerType())).alias('film_age'), f.col('genres'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Группирую данные, чтобы узнать, сколько юзер посмотрел фильмов (потом эта фича не используется, так как она ухудшала результаты) и сколько юзеров посмотрели фильм. Проще говоря, узнаю активность и популярность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_user = train.select('user_id', 'item_id').distinct().groupBy('user_id').agg(f.count('item_id').alias('v_user'))\n",
    "\n",
    "v_item = train.select('user_id', 'item_id').distinct().groupBy('item_id').agg(f.count('user_id').alias('v_item'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### На этом этапе нахожу, сколько  в среднем часов (adjusted mean) провёл каждый юзер за просмотром контента и применяю MinMaxScale на данный показатель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = spark.read.csv(\"/labs/lab10data/lab10_views_programmes.csv\", sep=',', header=True)\\\n",
    ".select(f.col('user_id'), f.col('ts_start').cast(LongType()), f.col('ts_end').cast(LongType()))\\\n",
    ".select(f.col('user_id'), f.round((f.col('ts_end')-f.col('ts_start'))/3600, 2).alias('hours_spend'))\\\n",
    ".fillna(1.04, subset=['hours_spend'])\\\n",
    ".groupBy('user_id').agg(f.sum('hours_spend').alias(\"sum_hours_spend\"),\n",
    "                        f.count('hours_spend').alias(\"count_hours_spend\"))\\\n",
    ".select(f.col('user_id'),\n",
    "        f.round((f.col('sum_hours_spend')+(250*1.04))/(f.col('count_hours_spend')+250), 2)\\\n",
    "        .alias('hours_spend'),\n",
    "        f.round((f.col('count_hours_spend')-1.0)/(113796.0-1.0), 4).alias('adj_views'))\\\n",
    ".cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Токенизатор жанров контента (каждый item мог иметь более одного жанра). Сейчас бы я применил на этом моменте заранее подготовленную Scala UDF, но тогда я этого не умел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@f.pandas_udf(ArrayType(StringType()))\n",
    "def presplit(dataseries):\n",
    "    return dataseries.apply(lambda x: x.split(',') if x != None else [])\n",
    "\n",
    "@f.pandas_udf(ArrayType(StringType()))\n",
    "def split(dataseries):\n",
    "    return dataseries.apply(lambda x: [y.lower() for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.withColumn('genres', presplit('genres'))\n",
    "items = items.withColumn('genres', split('genres'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_two_lists(x, y):\n",
    "    z = x.copy()\n",
    "    return z + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_schema = StructType(fields=[StructField(\"user_id\", StringType()),\n",
    "                               StructField(\"genres\", ArrayType(StringType()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_u_schema = StructType(fields=[StructField(\"user_id\", StringType()),\n",
    "                               StructField(\"u_features\", ArrayType(DoubleType()))])\n",
    "\n",
    "res_i_schema = StructType(fields=[StructField(\"item_id\", StringType()),\n",
    "                               StructField(\"i_features\", ArrayType(DoubleType()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pref = train.where(f.col('purchase')==1.0)\\\n",
    ".join(items.select(f.col('item_id'), f.col('genres')), on='item_id', how='left')\\\n",
    ".select(f.col('user_id'), f.col('genres'))\\\n",
    ".rdd.map(lambda x: (x[0], x[1])).reduceByKey(merge_two_lists, numPartitions=1)\\\n",
    ".toDF(schema=u_schema).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применяю CountVectorizer к жанрам, что представить жанровую принадлежность item в виде числового вектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol=\"genres\", outputCol=\"features\", minDF=2.0)\n",
    "\n",
    "model = cv.fit(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_items = model.transform(items)\\\n",
    ".select(f.col('item_id'), f.col('features'))\\\n",
    ".rdd.map(lambda x: (x[0], x[1].toArray().tolist()))\\\n",
    ".toDF(schema=res_i_schema).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применяю тот же подход к юзерам => задача - определить любимые (самые часто просматриваемые) жанры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_users = model.transform(user_pref)\\\n",
    ".select(f.col('user_id'), f.col('features'))\\\n",
    ".rdd.map(lambda x: (x[0], x[1].toArray().tolist()))\\\n",
    ".toDF(schema=res_u_schema).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: string, genres: array<string>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_pref.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_all_schema = StructType(fields=[StructField(\"user_id\", StringType()),\n",
    "                                    StructField(\"item_id\", StringType()),\n",
    "                                    StructField(\"features\", ArrayType(DoubleType()))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создаю вектор для холодного старта. Если у контента не было указано жанра, то он получает нулевой векток, если у юзера, то вектор из единиц (считаем, что все жанры нравятся ему одинаково).\n",
    "#### Делю вектор юзера на его длину.\n",
    "#### И нахожу пересечения векторов контента и юзера (идея: предугадываем по жанру вероятность того, что контент понравится)\n",
    "#### Дополнительно нахожу для test, покупал ли юзер что-то раньше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_array_user = [1.0 for i in range(75)]\n",
    "cold_array_film = [0.0 for i in range(75)]\n",
    "\n",
    "res_all = test.drop('purchase').union(train.drop('purchase'))\\\n",
    ".join(res_items, on='item_id', how='left')\\\n",
    ".join(res_users, on='user_id', how='left')\\\n",
    ".select(f.col('user_id'), f.col('item_id'), f.col(\"u_features\"), f.col(\"i_features\"))\\\n",
    ".rdd.map(lambda x: (x[0], x[1], x[2], x[3]) if x[2] != None else (x[0], x[1], cold_array_user, x[3]))\\\n",
    ".map(lambda x: (x[0], x[1], x[2], x[3]) if x[3] != None else (x[0], x[1], x[2], cold_array_film))\\\n",
    ".map(lambda x: (x[0], x[1], ((np.array(x[2])/(np.array(x[2]).sum()+0.000001))*np.array(x[3])).tolist()))\\\n",
    ".toDF(schema=res_all_schema)\\\n",
    ".join(items.select(f.col('item_id'), f.col('film_age')), on='item_id').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[item_id: string, film_age: int, genres: array<string>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[item_id: string, i_features: array<double>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_items.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: string, u_features: array<double>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_users.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дообрабатываем тренировочные и тестовые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_test = test.join(res_all, on=['item_id', 'user_id'], how='left').join(details, on='user_id', how='left')\\\n",
    ".join(v_user, on='user_id', how='left').join(v_item, on='item_id', how='left')\\\n",
    ".select(f.col('user_id'), f.col('item_id'),\n",
    "        f.col('film_age'), f.col('features'), f.col('hours_spend'),\n",
    "        f.when(f.col('hours_spend').isNull(), 0.0).otherwise(1.0).alias('hours_inffered'),\n",
    "        f.col('adj_views'), f.col('v_user'), f.col('v_item'), f.col('purchase')).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train = train.join(res_all, on=['item_id', 'user_id'], how='left').join(details, on='user_id', how='left')\\\n",
    ".join(v_user, on='user_id', how='left').join(v_item, on='item_id', how='left')\\\n",
    ".select(f.col('user_id'), f.col('item_id'),\n",
    "        f.col('film_age'), f.col('features'), f.col('hours_spend'),\n",
    "        f.when(f.col('hours_spend').isNull(), 0.0).otherwise(1.0).alias('hours_inffered'),      \n",
    "        f.col('adj_views'), f.col('v_user'), f.col('v_item'), f.col('purchase')).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[item_id: string, user_id: string, features: array<double>, film_age: int]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: string, hours_spend: double, adj_views: double]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Переносим результат предыдущих этапов в pandas, так как впереди мудрёная запись в формат .libfm (встроенную запись в формат .libsvm использовать не удалось)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = w_test\\\n",
    ".select('user_id', 'item_id', 'film_age', 'hours_spend', 'hours_inffered',\n",
    "        'adj_views', 'purchase',\n",
    "        'v_user', 'v_item', 'features')\\\n",
    ".toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = w_train\\\n",
    ".select('user_id', 'item_id', 'film_age', 'hours_spend', 'hours_inffered',\n",
    "        'adj_views', 'purchase',\n",
    "        'v_user', 'v_item', 'features')\\\n",
    ".toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: string, item_id: string, film_age: int, features: array<double>, hours_spend: double, hours_inffered: double, adj_views: double, v_user: bigint, v_item: bigint, purchase: double]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_test.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: string, item_id: string, film_age: int, features: array<double>, hours_spend: double, hours_inffered: double, adj_views: double, v_user: bigint, v_item: bigint, purchase: double]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_train.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Заполняем оставшиеся пробелы 0, средним или медианой, в зависимости от фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['purchase'].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.astype({'user_id': int,\n",
    "                            'item_id':int})\n",
    "\n",
    "test_df = test_df.astype({'user_id': int,\n",
    "                          'item_id':int})\n",
    "\n",
    "train_df.sort_values(by = ['user_id', 'item_id'], ascending=[True, True], inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.sort_values(by = ['user_id', 'item_id'], ascending=[True, True], inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['film_age'].fillna(train_df['film_age'].min(), inplace=True)\n",
    "test_df['film_age'].fillna(test_df['film_age'].min(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['hours_spend'].fillna(train_df['hours_spend'].median(), inplace=True)\n",
    "test_df['hours_spend'].fillna(test_df['hours_spend'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['adj_views'].fillna(train_df['adj_views'].median(), inplace=True)\n",
    "test_df['adj_views'].fillna(test_df['adj_views'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['v_item'].fillna(0, inplace=True)\n",
    "test_df['v_item'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna(train_df.median(), inplace=True)\n",
    "test_df.fillna(test_df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = train_df[train_df['purchase']==1.0][['user_id', 'purchase']].copy().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.rename(columns={'purchase':'bought_before'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_df, b, how = 'left', on = 'user_id')\n",
    "train_df['bought_before'].fillna(0.0, inplace=True)\n",
    "\n",
    "test_df = pd.merge(test_df, b, how = 'left', on = 'user_id')\n",
    "test_df['bought_before'].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применяю MinMaxScaler на возраст фильма (кастомный был быстрее встроенного в sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(df, column):\n",
    "    x_min = df[column].min()\n",
    "    x_max = df[column].max()\n",
    "    \n",
    "    return df[column].apply(lambda x: (x-x_min)/(x_max-x_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['film_age'] = min_max_scaler(train_df, 'film_age')\n",
    "test_df['film_age'] = min_max_scaler(test_df, 'film_age')\n",
    "\n",
    "train_df['v_item'] = min_max_scaler(train_df, 'v_item')\n",
    "test_df['v_item'] = min_max_scaler(test_df, 'v_item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([train_df, test_df]) \n",
    "full_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Далее провожу ручную конвертацию в формат .libfm (чем-то схоже со sparse матрицами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = list(set(full_df['user_id']))\n",
    "users.sort()\n",
    "\n",
    "user_dic = {}\n",
    "for idx, usr in enumerate(users):\n",
    "    user_dic[usr] = idx\n",
    "\n",
    "full_df['fm_user'] = full_df['user_id'].apply(lambda x: str(user_dic[x])+':1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "point1=len(user_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "films = list(set(full_df['item_id']))\n",
    "films.sort()\n",
    "\n",
    "film_dic = {}\n",
    "for idx, flm in enumerate(films):\n",
    "    film_dic[flm] = idx+point1\n",
    "\n",
    "full_df['fm_item'] = full_df['item_id'].apply(lambda x: str(film_dic[x])+':1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "point2 = point1+len(film_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['film_age'] = full_df['film_age'].apply(lambda x: str(point2) + ':' + str(float(\"{0:.4f}\".format(x))))\n",
    "full_df['hours_spend'] = full_df['hours_spend'].apply(lambda x: str(point2+1) + ':' + str(float(\"{0:.4f}\".format(x))))\n",
    "\n",
    "full_df['hours_inffered'] = full_df['hours_inffered'].apply(lambda x: str(point2+2) + ':' + str(float(\"{0:.1f}\".format(x))))\n",
    "full_df['adj_views'] = full_df['adj_views'].apply(lambda x: str(point2+3) + ':' + str(float(\"{0:.4f}\".format(x))))\n",
    "\n",
    "full_df['bought_before'] = full_df['bought_before'].apply(lambda x: str(point2+4) + ':' + str(float(\"{0:.1f}\".format(x))))\n",
    "full_df['v_item'] = full_df['v_item'].apply(lambda x: str(point2+5) + ':' + str(float(\"{0:.4f}\".format(x))))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#full_df['features'] = full_df['features'].apply(lambda x: str(point2+7) + ':' + str(float(\"{0:.4f}\".format(x.sum()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df[['purchase', 'fm_user', 'fm_item', 'film_age', 'hours_spend',\n",
    "                   'hours_inffered', 'adj_views', 'bought_before', 'v_item', 'features']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверяю промежуточный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase</th>\n",
       "      <th>fm_user</th>\n",
       "      <th>fm_item</th>\n",
       "      <th>film_age</th>\n",
       "      <th>hours_spend</th>\n",
       "      <th>hours_inffered</th>\n",
       "      <th>adj_views</th>\n",
       "      <th>bought_before</th>\n",
       "      <th>v_item</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0:1</td>\n",
       "      <td>1941:1</td>\n",
       "      <td>5645:0.0495</td>\n",
       "      <td>5646:0.81</td>\n",
       "      <td>5647:1.0</td>\n",
       "      <td>5648:0.0017</td>\n",
       "      <td>5649:1.0</td>\n",
       "      <td>5650:0.6233</td>\n",
       "      <td>[0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0:1</td>\n",
       "      <td>1943:1</td>\n",
       "      <td>5645:0.0495</td>\n",
       "      <td>5646:0.81</td>\n",
       "      <td>5647:1.0</td>\n",
       "      <td>5648:0.0017</td>\n",
       "      <td>5649:1.0</td>\n",
       "      <td>5650:0.5205</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2499999687500...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0:1</td>\n",
       "      <td>1944:1</td>\n",
       "      <td>5645:0.099</td>\n",
       "      <td>5646:0.81</td>\n",
       "      <td>5647:1.0</td>\n",
       "      <td>5648:0.0017</td>\n",
       "      <td>5649:1.0</td>\n",
       "      <td>5650:0.6164</td>\n",
       "      <td>[0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0:1</td>\n",
       "      <td>1945:1</td>\n",
       "      <td>5645:0.0693</td>\n",
       "      <td>5646:0.81</td>\n",
       "      <td>5647:1.0</td>\n",
       "      <td>5648:0.0017</td>\n",
       "      <td>5649:1.0</td>\n",
       "      <td>5650:0.7603</td>\n",
       "      <td>[0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0:1</td>\n",
       "      <td>1946:1</td>\n",
       "      <td>5645:0.0891</td>\n",
       "      <td>5646:0.81</td>\n",
       "      <td>5647:1.0</td>\n",
       "      <td>5648:0.0017</td>\n",
       "      <td>5649:1.0</td>\n",
       "      <td>5650:0.6027</td>\n",
       "      <td>[0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchase fm_user fm_item     film_age hours_spend hours_inffered  \\\n",
       "0       0.0     0:1  1941:1  5645:0.0495   5646:0.81       5647:1.0   \n",
       "1       0.0     0:1  1943:1  5645:0.0495   5646:0.81       5647:1.0   \n",
       "2       0.0     0:1  1944:1   5645:0.099   5646:0.81       5647:1.0   \n",
       "3       0.0     0:1  1945:1  5645:0.0693   5646:0.81       5647:1.0   \n",
       "4       0.0     0:1  1946:1  5645:0.0891   5646:0.81       5647:1.0   \n",
       "\n",
       "     adj_views bought_before       v_item  \\\n",
       "0  5648:0.0017      5649:1.0  5650:0.6233   \n",
       "1  5648:0.0017      5649:1.0  5650:0.5205   \n",
       "2  5648:0.0017      5649:1.0  5650:0.6164   \n",
       "3  5648:0.0017      5649:1.0  5650:0.7603   \n",
       "4  5648:0.0017      5649:1.0  5650:0.6027   \n",
       "\n",
       "                                            features  \n",
       "0  [0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2499999687500...  \n",
       "2  [0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "3  [0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4  [0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 6\n",
    "\n",
    "for el in range(75):\n",
    "    full_df['f_'+str(el)] = full_df['features'].apply(lambda x: str(point2+num) + ':' + str(float(\"{0:.4f}\".format(x[el]))))\n",
    "    num+=1\n",
    "    \n",
    "full_df.drop('features', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_train = full_df.iloc[0:train_df.shape[0],:]\n",
    "fm_test = full_df.iloc[train_df.shape[0]:,:]\n",
    "\n",
    "fm_test['purchase'].fillna(0, inplace=True)\n",
    "fm_test['purchase'] = fm_test['purchase'].astype(int)\n",
    "fm_train['purchase'] = fm_train['purchase'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_train.to_csv('train.libfm', header = None, index = False, sep = ' ')\n",
    "fm_test.to_csv('test.libfm', header = None, index = False, sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's/\"//g' train.libfm \n",
    "!sed -i 's/\"//g' test.libfm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сверяюсь, что ничего не забыл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>film_age</th>\n",
       "      <th>hours_spend</th>\n",
       "      <th>hours_inffered</th>\n",
       "      <th>adj_views</th>\n",
       "      <th>purchase</th>\n",
       "      <th>v_user</th>\n",
       "      <th>v_item</th>\n",
       "      <th>features</th>\n",
       "      <th>bought_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1654</td>\n",
       "      <td>326</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2568</td>\n",
       "      <td>0.623288</td>\n",
       "      <td>[0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1654</td>\n",
       "      <td>357</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2568</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2499999687500...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1654</td>\n",
       "      <td>396</td>\n",
       "      <td>0.099010</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2568</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>[0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1654</td>\n",
       "      <td>400</td>\n",
       "      <td>0.069307</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2568</td>\n",
       "      <td>0.760274</td>\n",
       "      <td>[0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1654</td>\n",
       "      <td>423</td>\n",
       "      <td>0.089109</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2568</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>[0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  film_age  hours_spend  hours_inffered  adj_views  \\\n",
       "0     1654      326  0.049505         0.81             1.0     0.0017   \n",
       "1     1654      357  0.049505         0.81             1.0     0.0017   \n",
       "2     1654      396  0.099010         0.81             1.0     0.0017   \n",
       "3     1654      400  0.069307         0.81             1.0     0.0017   \n",
       "4     1654      423  0.089109         0.81             1.0     0.0017   \n",
       "\n",
       "   purchase  v_user    v_item  \\\n",
       "0       0.0    2568  0.623288   \n",
       "1       0.0    2568  0.520548   \n",
       "2       0.0    2568  0.616438   \n",
       "3       0.0    2568  0.760274   \n",
       "4       0.0    2568  0.602740   \n",
       "\n",
       "                                            features  bought_before  \n",
       "0  [0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...            1.0  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2499999687500...            1.0  \n",
       "2  [0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...            1.0  \n",
       "3  [0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...            1.0  \n",
       "4  [0.12499998437500197, 0.0, 0.0, 0.0, 0.0, 0.0,...            1.0  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0:1 1941:1 5645:0.0495 5646:0.81 5647:1.0 5648:0.0017 5649:1.0 5650:0.125 5651:0.0 5652:0.0 5653:0.0 5654:0.0 5655:0.0 5656:0.0 5657:0.0 5658:0.0 5659:0.0 5660:0.0 5661:0.0 5662:0.0 5663:0.0 5664:0.0 5665:0.0 5666:0.0 5667:0.0 5668:0.0 5669:0.0 5670:0.0 5671:0.0 5672:0.0 5673:0.0 5674:0.0 5675:0.0 5676:0.0 5677:0.0 5678:0.0 5679:0.0 5680:0.0 5681:0.0 5682:0.0 5683:0.0 5684:0.0 5685:0.0 5686:0.0 5687:0.0 5688:0.0 5689:0.0 5690:0.0 5691:0.0 5692:0.0 5693:0.0 5694:0.0 5695:0.0 5696:0.0 5697:0.0 5698:0.0 5699:0.0 5700:0.0 5701:0.0 5702:0.0 5703:0.0 5704:0.0 5705:0.0 5706:0.0 5707:0.0 5708:0.0 5709:0.0 5710:0.0 5711:0.0 5712:0.0 5713:0.0 5714:0.0 5715:0.0 5716:0.0 5717:0.0 5718:0.0 5719:0.0 5720:0.0 5721:0.0 5722:0.0 5723:0.0 5724:0.0\r\n"
     ]
    }
   ],
   "source": [
    "!head -n1 train.libfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0:1 1941:1 5645:0.0495 5646:0.81 5647:1.0 5648:0.0017 5649:1.0 5650:0.6233 5651:0.125 5652:0.0 5653:0.0 5654:0.0 5655:0.0 5656:0.0 5657:0.0 5658:0.0 5659:0.0 5660:0.0 5661:0.0 5662:0.0 5663:0.0 5664:0.0 5665:0.0 5666:0.0 5667:0.0 5668:0.0 5669:0.0 5670:0.0 5671:0.0 5672:0.0 5673:0.0 5674:0.0 5675:0.0 5676:0.0 5677:0.0 5678:0.0 5679:0.0 5680:0.0 5681:0.0 5682:0.0 5683:0.0 5684:0.0 5685:0.0 5686:0.0 5687:0.0 5688:0.0 5689:0.0 5690:0.0 5691:0.0 5692:0.0 5693:0.0 5694:0.0 5695:0.0 5696:0.0 5697:0.0 5698:0.0 5699:0.0 5700:0.0 5701:0.0 5702:0.0 5703:0.0 5704:0.0 5705:0.0 5706:0.0 5707:0.0 5708:0.0 5709:0.0 5710:0.0 5711:0.0 5712:0.0 5713:0.0 5714:0.0 5715:0.0 5716:0.0 5717:0.0 5718:0.0 5719:0.0 5720:0.0 5721:0.0 5722:0.0 5723:0.0 5724:0.0 5725:0.0\r\n"
     ]
    }
   ],
   "source": [
    "!head -n1 train.libfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df = pd.concat([train_df, test_df]) \n",
    "f_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "prob = pd.read_csv('prob1.txt', header = None)\n",
    "out_test = f_df.iloc[train_df.shape[0]:,0:2]\n",
    "out_test.reset_index(drop=True, inplace=True)\n",
    "out_test['purchase'] = prob\n",
    "out_test.to_csv('lab10s(1_1).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### После применяю файл на ALS в libfm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итог: первое место среди все учащихся на соревновании"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image.jpg\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
